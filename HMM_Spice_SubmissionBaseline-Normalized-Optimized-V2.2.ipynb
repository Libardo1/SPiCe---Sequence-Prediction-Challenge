{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from math import expm1\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeInitialProb(trainDataFile,numOfStates):\n",
    "    trainFile=open(trainDataFile,\"r\")\n",
    "    metaDataLine = trainFile.readline()\n",
    "    headerLine = metaDataLine.split(\" \")\n",
    "    numSequences = int(headerLine[0])\n",
    "    distinctObservations= int(headerLine[1])#Total Number of Distinct Observations\n",
    "    numOfStates=min(numOfStates,distinctObservations)\n",
    "    empiricalCount=np.zeros(shape=numOfStates)\n",
    "    empiricalFreq=defaultdict(int)\n",
    "    for n in range(numSequences):\n",
    "        line = trainFile.readline()#Reading Sequences 1 by 1\n",
    "        l = line.split(\" \")\n",
    "        startState=int(l[1])\n",
    "        empiricalFreq[startState] = empiricalFreq[startState]+1\n",
    "    totalObservations=0\n",
    "    for i in np.arange(numOfStates):\n",
    "        empiricalCount[i]=empiricalFreq[i]\n",
    "        totalObservations=totalObservations+empiricalCount[i]\n",
    "    initialProb=[count/totalObservations for count in empiricalCount]\n",
    "    return (numOfStates,distinctObservations,initialProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createRandomMatrixA(numOfStates):\n",
    "    matrixA=np.ndarray(shape=(numOfStates,numOfStates),dtype=float)\n",
    "    prob=1.0/(numOfStates*numOfStates)\n",
    "    matrixA.fill(prob)\n",
    "    return matrixA\n",
    "def createRandomMatrixB(numOfStates,distinctObservations):\n",
    "    matrixB=np.ndarray(shape=(numOfStates,distinctObservations),dtype=float)\n",
    "    prob=1.0/(numOfStates*distinctObservations)\n",
    "    matrixB.fill(prob)\n",
    "    return matrixB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeAlpha(observations,a,aTranspose,b,bTranspose,pi,alphaDP):\n",
    "    statesC=a.shape[0]\n",
    "    timePts=observations.shape[0]\n",
    "    if timePts<1:\n",
    "        return\n",
    "    alphaDpScaleTime0=0\n",
    "    #bTranspose=b.transpose()\n",
    "    alphaDP[0]=pi*bTranspose[observations[0]]\n",
    "    alphaDpScaleTime0=np.sum(alphaDP[0])\n",
    "    alphaDP[0]/=alphaDpScaleTime0\n",
    "    #aTranspose=a.transpose()\n",
    "    for t in np.arange(1,timePts):\n",
    "        alphaDpScaleTimeT=0\n",
    "        for i in np.arange(statesC):\n",
    "            alphaDP[t][i]=(np.sum(alphaDP[t-1]*aTranspose[i]))*b[i][observations[t]]\n",
    "        alphaDpScaleTimeT=np.sum(alphaDP[t])\n",
    "        alphaDP[t]/=alphaDpScaleTimeT\n",
    "def observationsLikelihood(alphaDP):\n",
    "    timePts=alphaDP.shape[0]\n",
    "    ans=0.0\n",
    "    ans=np.sum(alphaDP[timePts-1])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeBeta(observations,a,b,bTranspose,pi,betaDP):\n",
    "    statesC=a.shape[0]\n",
    "    timePts=observations.shape[0]\n",
    "    if timePts<1:\n",
    "        return\n",
    "    betaDP[timePts-1].fill(1)\n",
    "    #bTranspose=b.transpose()\n",
    "    for t in np.arange(timePts-2,-1,-1):\n",
    "        betaDpScaleTimeT=0\n",
    "        for i in np.arange(statesC):\n",
    "            betaDP[t][i]=np.sum(a[i]*bTranspose[observations[t+1]]*betaDP[t+1])\n",
    "        betaDpScaleTimeT=np.sum(betaDP[t])\n",
    "        betaDP[t]/=betaDpScaleTimeT\n",
    "    return betaDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeDiGammaDP(alphaDP,betaDP,a,b,bTranspose,observations):\n",
    "    observationsC=alphaDP.shape[0]\n",
    "    statesC=alphaDP.shape[1]\n",
    "    diGammaDP=np.zeros(shape=(statesC,statesC),dtype=float)\n",
    "    diGammaDenom=observationsLikelihood(alphaDP)\n",
    "    #bTranspose=b.transpose()\n",
    "    for i in np.arange(statesC):\n",
    "        for t in np.arange(observationsC-1):\n",
    "            diGammaDP[i]+=alphaDP[t][i]*a[i]*bTranspose[observations[t+1]]*betaDP[t+1]\n",
    "    diGammaDP/=diGammaDenom\n",
    "    return diGammaDP\n",
    "def computeTransitionProbabilityA(alphaDP,betaDP,a,b,bTranspose,observations):\n",
    "    statesC=alphaDP.shape[1]\n",
    "    newlyComputedTransitionProbA=np.zeros(shape=(statesC,statesC),dtype=float)\n",
    "    diGammaDP=computeDiGammaDP(alphaDP,betaDP,a,b,bTranspose,observations)\n",
    "    diGammaDPSumGrpByJ=np.apply_along_axis(np.sum,1,diGammaDP)\n",
    "    for i in np.arange(statesC):    \n",
    "        if (diGammaDPSumGrpByJ[i]==0):\n",
    "            newlyComputedTransitionProbA[i]=0.0\n",
    "        else:\n",
    "            newlyComputedTransitionProbA[i]=diGammaDP[i]/diGammaDPSumGrpByJ[i]\n",
    "    return newlyComputedTransitionProbA   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeGammaDP(alphaDP,betaDP):\n",
    "    gammaDenom=observationsLikelihood(alphaDP)\n",
    "    gammaDP=alphaDP*betaDP#[Time][State]\n",
    "    gammaDP/=gammaDenom\n",
    "    return gammaDP\n",
    "def computeTransitionProbabilityB(alphaDP,betaDP,a,b,observations,observationDict):\n",
    "    statesC=a.shape[0]\n",
    "    observationsC=b.shape[1]\n",
    "    newlyComputedObsrProbB=np.zeros(shape=(observationsC,statesC),dtype=float)#Ideal Shape should be transposed\n",
    "    gammaDP=computeGammaDP(alphaDP,betaDP)#[t][state]\n",
    "    obsrProbDenomVec=np.apply_along_axis(np.sum,0,gammaDP)#Sum Across Rows i.e. Across each state\n",
    "    for vk in observationDict:\n",
    "            newlyComputedObsrProbB[vk]=np.sum(gammaDP[np.where(observations==vk)])/obsrProbDenomVec\n",
    "    newlyComputedObsrProbB=newlyComputedObsrProbB.transpose()#Back to Shape[i][vk]\n",
    "    return newlyComputedObsrProbB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Change Convergence Criteria to be more reasonable/Useful\n",
    "def isConverged(count,convergenceIters):\n",
    "    if count>=convergenceIters:\n",
    "        return True\n",
    "    return False\n",
    "def Forward_Backward_EM_Algo(observations,A,B,pi,convergenceIters,observationDict):\n",
    "    count=0\n",
    "    updatedA=A\n",
    "    updatedB=B\n",
    "    while isConverged(count,convergenceIters)==False:\n",
    "        #Expectation(E)-Step\n",
    "        alphaDP=np.zeros(shape=(observations.shape[0],updatedA.shape[0]))# Count_of_Observations*Count_of_Hidden_States\n",
    "        betaDP=np.zeros(shape=(observations.shape[0],updatedA.shape[0]))# Count_of_Observations*Count_of_Hidden_States\n",
    "        updatedATranspose=updatedA.transpose()\n",
    "        updatedBTranspose=updatedB.transpose()\n",
    "        computeAlpha(observations,updatedA,updatedATranspose,updatedB,updatedBTranspose,pi,alphaDP)\n",
    "        computeBeta(observations,updatedA,updatedB,updatedBTranspose,pi,betaDP)\n",
    "        #Maximization(M)-Step\n",
    "        newA=computeTransitionProbabilityA(alphaDP,betaDP,updatedA,updatedB,updatedBTranspose,observations)\n",
    "        newB=computeTransitionProbabilityB(alphaDP,betaDP,updatedA,updatedB,observations,observationDict)\n",
    "        updatedA=newA\n",
    "        updatedB=newB\n",
    "        count=count+1\n",
    "    return (updatedA,updatedB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainHMM(trainDataFile,A,B,pi,convergenceIters,maxSequences=-1):\n",
    "    trainFile=open(trainDataFile,\"r\")\n",
    "    metaDataLine = trainFile.readline()\n",
    "    headerLine = metaDataLine.split(\" \")\n",
    "    numSequences = int(headerLine[0])\n",
    "    distinctObservations= int(headerLine[1])#Total Number of Distinct Observations\n",
    "    observationDict=np.arange(distinctObservations)\n",
    "    updatedA=np.NaN\n",
    "    updatedB=np.NaN\n",
    "    isAUpdated=False\n",
    "    if(maxSequences==-1):\n",
    "        usedSeqs=numSequences\n",
    "    else:\n",
    "        usedSeqs=min(maxSequences,numSequences)\n",
    "    actuallyUsedSeqs=0\n",
    "    for n in range(usedSeqs):\n",
    "        line = trainFile.readline()#Reading Sequences 1 by 1\n",
    "        l = line.split(\" \")\n",
    "        if(int(l[0])<=1):\n",
    "            continue\n",
    "        actuallyUsedSeqs+=1\n",
    "        observations=np.array([int(i) for i in l[1:len(l)]])\n",
    "        learnedParams=Forward_Backward_EM_Algo(observations,A,B,pi,convergenceIters,observationDict)\n",
    "        if isAUpdated==False:\n",
    "            isAUpdated=True\n",
    "            updatedA=learnedParams[0]\n",
    "            updatedB=learnedParams[1]\n",
    "        else:\n",
    "            updatedA+=learnedParams[0]\n",
    "            updatedB+=learnedParams[1]\n",
    "    updatedA=updatedA/actuallyUsedSeqs\n",
    "    updatedB=updatedB/actuallyUsedSeqs\n",
    "    return (updatedA,updatedB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trainModel(fileLoc,maxNoOfStates,convergenceIters,maxSequences=-1):\n",
    "    start = time.time()\n",
    "    initialProbs=computeInitialProb(fileLoc,maxNoOfStates)\n",
    "    end = time.time()\n",
    "    print(\"Computed Initial Prob. in \", end - start ,\"seconds\")\n",
    "    pi=initialProbs[2]\n",
    "    numOfStates=initialProbs[0]\n",
    "    distinctObservations=initialProbs[1]\n",
    "    A=createRandomMatrixA(numOfStates)\n",
    "    B=createRandomMatrixB(numOfStates,distinctObservations)\n",
    "    trainedParams=trainHMM(fileLoc,A,B,pi,convergenceIters,maxSequences)\n",
    "    trainedParams=trainedParams+(pi,)\n",
    "    end=time.time()\n",
    "    print(\"For \",maxSequences,\" Sequences : Total Training Time \",end-start,\" seconds\")\n",
    "    return trainedParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Initial Prob. in  0.373828649520874 seconds\n",
      "For  1  Sequences : Total Training Time  1.0151755809783936  seconds\n"
     ]
    }
   ],
   "source": [
    "(A,B)=trainModel('Data/1.spice.train.txt',20,7,1)\n",
    "#(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Initial Prob. in  0.16173624992370605 seconds\n",
      "For  15  Sequences : Total Training Time  4.560023069381714  seconds\n",
      "Computed Initial Prob. in  0.15972256660461426 seconds\n",
      "For  15  Sequences : Total Training Time  4.6220409870147705  seconds\n",
      "Computed Initial Prob. in  0.15830111503601074 seconds\n",
      "For  15  Sequences : Total Training Time  4.576323509216309  seconds\n",
      "Computed Initial Prob. in  0.1583256721496582 seconds\n",
      "For  15  Sequences : Total Training Time  4.626648426055908  seconds\n",
      "1 loops, best of 3: 4.58 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit trainModel('Data/1.spice.train.txt',20,7,15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Initial Prob. in  0.16886186599731445 seconds\n",
      "For  15  Sequences : Total Training Time  4.5674731731414795  seconds\n",
      "Computed Initial Prob. in  0.196702241897583 seconds\n",
      "For  15  Sequences : Total Training Time  4.59807562828064  seconds\n",
      "Computed Initial Prob. in  0.15811681747436523 seconds\n",
      "For  15  Sequences : Total Training Time  4.655432939529419  seconds\n",
      "Computed Initial Prob. in  0.22752022743225098 seconds\n",
      "For  15  Sequences : Total Training Time  4.61660361289978  seconds\n",
      "1 loops, best of 3: 4.6 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit trainModel('Data/1.spice.train.txt',20,7,15)\n",
    "#(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Initial Prob. in  0.16386866569519043 seconds\n",
      "For  150  Sequences : Total Training Time  49.785178661346436  seconds\n",
      "Computed Initial Prob. in  0.16109967231750488 seconds\n",
      "For  150  Sequences : Total Training Time  51.17705059051514  seconds\n",
      "Computed Initial Prob. in  0.22313308715820312 seconds\n",
      "For  150  Sequences : Total Training Time  50.26441955566406  seconds\n",
      "Computed Initial Prob. in  0.15892481803894043 seconds\n",
      "For  150  Sequences : Total Training Time  49.6641047000885  seconds\n",
      "1 loops, best of 3: 49.7 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit trainModel('Data/1.spice.train.txt',20,7,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Initial Prob. in  0.15481114387512207 seconds\n",
      "For  150  Sequences : Total Training Time  2.766151189804077  seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.25065612,  0.25065612,  0.25065612,  0.13614352],\n",
       "        [ 0.25065612,  0.25065612,  0.25065612,  0.13614352],\n",
       "        [ 0.25065612,  0.25065612,  0.25065612,  0.13614352],\n",
       "        [ 0.28793509,  0.28793509,  0.28793509,  0.13619472]]),\n",
       " array([[ 0.89089087,  0.66680948,  0.41210032,  2.25830004],\n",
       "        [ 0.89089087,  0.66680948,  0.41210032,  2.25830004],\n",
       "        [ 0.89089087,  0.66680948,  0.41210032,  2.25830004],\n",
       "        [ 0.83195173,  0.6505008 ,  0.41041104,  1.87133779]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainModel('Data/0.spice.train.txt',20,7,150)\n",
    "#(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Initial Prob. in  0.062479496002197266 seconds\n",
      "For  1500  Sequences : Total Training Time  24.869220495224  seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.24017683,  0.24017683,  0.24017683,  0.13540768],\n",
       "        [ 0.24017683,  0.24017683,  0.24017683,  0.13540768],\n",
       "        [ 0.24017683,  0.24017683,  0.24017683,  0.13540768],\n",
       "        [ 0.28817546,  0.28817546,  0.28817546,  0.13547361]]),\n",
       " array([[ 0.93656972,  0.57671503,  0.36336451,  2.41459482],\n",
       "        [ 0.93656972,  0.57671503,  0.36336451,  2.41459482],\n",
       "        [ 0.93656972,  0.57671503,  0.36336451,  2.41459482],\n",
       "        [ 0.90163462,  0.55596422,  0.3553712 ,  1.89068153]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A,B,pi)=trainModel('Data/0.spice.train.txt',20,7,1500)\n",
    "print(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Initial Prob. in  0.06518864631652832 seconds\n",
      "For  15000  Sequences : Total Training Time  254.3390028476715  seconds\n"
     ]
    }
   ],
   "source": [
    "(A,B,pi)=trainModel('Data/0.spice.train.txt',20,7,15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Initial Prob. in  0.06556081771850586 seconds\n",
      "For  -1  Sequences : Total Training Time  355.021213054657  seconds\n"
     ]
    }
   ],
   "source": [
    "(A,B,pi)=trainModel('Data/0.spice.train.txt',20,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.24010455,  0.24010455,  0.24010455,  0.13705686],\n",
       "        [ 0.24010455,  0.24010455,  0.24010455,  0.13705686],\n",
       "        [ 0.24010455,  0.24010455,  0.24010455,  0.13705686],\n",
       "        [ 0.28762596,  0.28762596,  0.28762596,  0.13712213]]), numpy.ndarray)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A,type(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a6=[2,3,4,5]\n",
    "a7=np.array(a6)\n",
    "print(a7,type(a7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getHmmRank(prefix,A,ATranspose,B,BTranspose,pi,uniqueSymbols):\n",
    "    likelihoods=[]\n",
    "    for i in np.arange(uniqueSymbols):\n",
    "        prefix.append(i)\n",
    "        observations=np.array(prefix)\n",
    "        alphaDP=np.zeros(shape=(observations.shape[0],A.shape[0]))# Count_of_Observations*Count_of_Hidden_States\n",
    "        computeAlpha(observations,B,ATranspose,B,BTranspose,pi,alphaDP)\n",
    "        obsrLikelihood=observationsLikelihood(alphaDP)\n",
    "        prefix.pop()\n",
    "        likelihoods.append((i,obsrLikelihood))\n",
    "        print(likelihoods[i])\n",
    "    ranks=[i[0] for i in likelihoods]\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_to_string(l):\n",
    "    s=str(l[0])\n",
    "    for x in l[1:]:\n",
    "        s+= \" \" + str(x)\n",
    "    return(s)\n",
    "def formatString(string_in):\n",
    "    \"\"\" Replace white spaces by %20 \"\"\"\n",
    "    return string_in.strip().replace(\" \", \"%20\")\n",
    "# State the problem number\n",
    "problem_number = '0'\n",
    "\n",
    "# and the user id (given during registration)\n",
    "user_id = '68'\n",
    "\n",
    "# name of this submission (no space or special character)\n",
    "\n",
    "name = \"hmm_Baseline\"\n",
    "\n",
    "train_file = 'Data/0.spice.train.txt'\n",
    "#(A,B,pi)=trainModel('Data/0.spice.train.txt',20,7)\n",
    "prefix_file = 'Data/0.spice.public.test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix  [3, 0, 3, 0, 1, 3, 3]\n",
      "(0, 1.0)\n",
      "(1, 1.0)\n",
      "(2, 1.0)\n",
      "(3, 1.0)\n",
      "[0, 1, 2, 3]\n",
      "Prefix number: 1 Ranking: 0 1 2 3 Prefix: 7 3 0 3 0 1 3 3\n"
     ]
    }
   ],
   "source": [
    "# get the test first prefix: the only element of the test set\n",
    "def get_first_prefix(test_file):\n",
    "    \"\"\" get the only prefix in test_file\n",
    "        This function is called for the public test file(Which only has 1 line)\n",
    "    \"\"\"\n",
    "    f = open(test_file)\n",
    "    prefix = f.readline()\n",
    "    f.close()\n",
    "    return prefix\n",
    "first_prefix = get_first_prefix(prefix_file)\n",
    "prefix_number=1\n",
    "# get the next symbol ranking on the first prefix\n",
    "p=first_prefix.split()\n",
    "prefix=[int(i) for i in p[1:len(p)]]#prefix holds the sequence of values in the public test file(Note:It has only 1 Seq)\n",
    "print(\"Prefix \",prefix)\n",
    "ranking=getHmmRank(prefix,A,A.transpose(),B,B.transpose(),pi,A.shape[0])\n",
    "print(ranking)\n",
    "ranking_string=list_to_string(ranking[:5])\n",
    "print(\"Prefix number: \" + str(prefix_number) + \" Ranking: \" + ranking_string + \" Prefix: \" + first_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24010455  0.24010455  0.24010455  0.13705686]\n",
      " [ 0.24010455  0.24010455  0.24010455  0.13705686]\n",
      " [ 0.24010455  0.24010455  0.24010455  0.13705686]\n",
      " [ 0.28762596  0.28762596  0.28762596  0.13712213]]\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.94886774  0.56048745  0.38347267  2.39554741]\n",
      " [ 0.94886774  0.56048745  0.38347267  2.39554741]\n",
      " [ 0.94886774  0.56048745  0.38347267  2.39554741]\n",
      " [ 0.91057537  0.54420096  0.37487202  1.87687201]]\n"
     ]
    }
   ],
   "source": [
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
